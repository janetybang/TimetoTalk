---
title: "Stability Across Activities - 7 categories; English and Spanish Separately"
author: "Janet Bang"
date: "November 17, 2022"
output:
  html_document: 
   toc: true
   toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(echo=TRUE, 
               warning=FALSE, message=FALSE, 
               cache=FALSE)

opts_chunk$set(fig.width = 12, fig.height = 8) 
```


This code is for the results to the question, "Is there stability across caregivers, regardless of activity?", but conducts analyses separately per language and for separate levels for all other-child-centered activities (see pre-registration here: https://osf.io/byjfg/).


## Load libraries
```{r}
library(tidyverse)
library(GGally)
library(ppcor)
library(psych)
library(Hmisc)
library(sjPlot)

# https://github.com/ggobi/ggally/issues/139
my_custom_smooth <- function(data, mapping, ...) {
  ggplot(data = data, mapping = mapping) +
    geom_point(alpha = .4, color = I("black")) + 
    geom_smooth(method = "lm", color = I("blue"), ...)
}
```


## Read in data and demographic information
```{r}
# NOTE about periods of non-tCDCS
# gemods refers to when there are designated start/end periods of other-directed speech (ODS); this was captured using gems (@G) using CHAT conventions
# kwalods refers to when ODS was transcribed at an utterance-level within a tCDS activity period between caregiver and child (e.g., other-directed speech in the background); this was captured per utterances using CHAT postcodes
## for tokens/min and types/min, we do not include ODS that occurred within a period of tCDS, because durations were captured by activity and not by utterance
## for mlu, we include all ODS across gemods and kwalods


# NOTE about speech == "all"
# "speech" includes two levels: all, spont
# all = refers to all speech by caregivers
# spont = refers to only speech by caregivers that was considered spontaneous rather than recited (e.g., reading book text, singing memorized common songs like itsy bitsy spider); therefore, 'spont' is a subset of 'all'


# freq
freq <- read_csv("./data_demo_lena_transcripts/freq.csv") %>% 
  filter(activity != "kwalods", 
         speech == "all") %>% 
  mutate(activity = recode(activity, "gemods" = "non_tcds")) %>% 
  mutate(id = factor(id), 
         language = factor(language),
         activity = factor(activity, levels = c("books", "play", "food", 
                                                "routines", "conv", "ac", "non_tcds")))



# mlu
mlu <- read_csv("./data_demo_lena_transcripts/mlu.csv") %>% 
  filter(speech == "all") %>% 
  mutate(activity = recode(activity, "ods" = "non_tcds")) %>% 
  mutate(id = factor(id), 
         language = factor(language),
         activity = factor(activity, levels = c("books", "play", "food", 
                                                "routines", "conv", "ac", "non_tcds")))


# chip
# this includes only caregivers, therefore there is no speaker column
# we exclude periods of ODS because this is about responsiveness to the child during periods of tCDS
chip <- read_csv("./data_demo_lena_transcripts/chip.csv") %>% 
  filter(activity != "ods") %>% 
  mutate(id = factor(id), 
         language = factor(language),
         activity = factor(activity, levels = c("books", "play", "food", 
                                                "routines", "conv", "ac", "non_tcds")))
  
  

str(freq)
str(mlu)
str(chip)
```




## Create dfs for ADULTS
```{r}
# FREQ
freq_adult_en <- freq %>% 
  filter(speaker == "ADULTS") %>% 
  filter(language == "english")

freq_adult_sp <- freq %>% 
  filter(speaker == "ADULTS") %>% 
  filter(language == "spanish")


# MLU
mlu_adult_en <- mlu %>% 
  filter(speaker == "ADULTS") %>% 
  filter(language == "english")

mlu_adult_sp <- mlu %>% 
  filter(speaker == "ADULTS") %>% 
  filter(language == "spanish")
```




# Create dfs averaging across segments for one obs per activity
## Tokens and Types (rate per min)
```{r}
# tokens and types: average per activity
freq_adult_per_activity_id_en <- freq_adult_en %>% 
  group_by(id, activity) %>% 
  mutate(tokens_permin_avg_act = mean(tokens_permin), 
         types_permin_avg_act = mean(types_permin)) %>% 
  distinct(id, activity, language, tokens_permin_avg_act, types_permin_avg_act) %>% 
  ungroup() %>% 
  mutate(activity = factor(activity, levels = c("books", "play", "food", 
                                                "routines", "conv", "ac", "non_tcds")))

freq_adult_per_activity_id_sp <- freq_adult_sp %>% 
  group_by(id, activity) %>% 
  mutate(tokens_permin_avg_act = mean(tokens_permin), 
         types_permin_avg_act = mean(types_permin)) %>% 
  distinct(id, activity, language, tokens_permin_avg_act, types_permin_avg_act) %>% 
  ungroup() %>% 
  mutate(activity = factor(activity, levels = c("books", "play", "food", 
                                                "routines", "conv", "ac", "non_tcds")))
```


## MLUw
```{r}
# mlu: average per activity
mlu_adult_per_activity_id_en <- mlu_adult_en %>% 
  group_by(id, activity) %>% 
  mutate(mluw_avg_act = mean(mlu_w)) %>% 
  distinct(id, activity, language, mluw_avg_act) %>% 
  ungroup() %>% 
  mutate(activity = factor(activity, levels = c("books", "play", "food", 
                                                "routines", "conv", "ac", "non_tcds")))

mlu_adult_per_activity_id_sp <- mlu_adult_sp %>% 
  group_by(id, activity) %>% 
  mutate(mluw_avg_act = mean(mlu_w)) %>% 
  distinct(id, activity, language, mluw_avg_act) %>% 
  ungroup() %>% 
  mutate(activity = factor(activity, levels = c("books", "play", "food", 
                                                "routines", "conv", "ac", "non_tcds")))
```



## Responses and Imitations/Expansions
```{r}
# chip: average per activity
chip_per_activity_id_en <- chip %>% 
  filter(language == "english") %>% 
  group_by(id, activity) %>% 
  mutate(prop_adultresp_avg_act = mean(prop_adultresp_outof_childutt, na.rm = T), 
         prop_adult_imitexp_avg_act = mean(prop_adult_imitexp_outof_childutt, na.rm = T)) %>% 
  distinct(id, activity, language, prop_adultresp_avg_act, prop_adult_imitexp_avg_act)


chip_per_activity_id_sp <- chip %>% 
  filter(language == "spanish") %>% 
  group_by(id, activity) %>% 
  mutate(prop_adultresp_avg_act = mean(prop_adultresp_outof_childutt, na.rm = T), 
         prop_adult_imitexp_avg_act = mean(prop_adult_imitexp_outof_childutt, na.rm = T)) %>% 
  distinct(id, activity, language, prop_adultresp_avg_act, prop_adult_imitexp_avg_act)
```




## Create wide dfs for matrices - tokens and types (rate)
```{r}
# tokens
# all
tokens_mtx_rate_en <- freq_adult_per_activity_id_en %>% 
  dplyr::select(id, language, activity, tokens_permin_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = tokens_permin_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac", "non_tcds"))

tokens_mtx_rate_sp <- freq_adult_per_activity_id_sp %>% 
  dplyr::select(id, language, activity, tokens_permin_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = tokens_permin_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac", "non_tcds"))


# types
# all
types_mtx_rate_en <- freq_adult_per_activity_id_en %>% 
  dplyr::select(id, language, activity, types_permin_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = types_permin_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac", "non_tcds"))

types_mtx_rate_sp <- freq_adult_per_activity_id_sp %>% 
  dplyr::select(id, language, activity, types_permin_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = types_permin_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac", "non_tcds"))

```



## Create wide dfs for matrices - mluw
```{r}
# all
mlu_mtx_en <- mlu_adult_per_activity_id_en %>% 
  dplyr::select(id, language, activity, mluw_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = mluw_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac", "non_tcds"))


mlu_mtx_sp <- mlu_adult_per_activity_id_sp %>% 
  dplyr::select(id, language, activity, mluw_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = mluw_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac", "non_tcds"))
```



## Create wide dfs for matrix - responses and imit/exp
```{r}
# prop responses
propresp_mtx_en <- chip_per_activity_id_en %>% 
  dplyr::select(id, language, activity, prop_adultresp_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = prop_adultresp_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac"))

propresp_mtx_sp <- chip_per_activity_id_sp %>% 
  dplyr::select(id, language, activity, prop_adultresp_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = prop_adultresp_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac"))



# prop imitations and expansions
propimitexp_mtx_en <- chip_per_activity_id_en %>% 
  dplyr::select(id, language, activity, prop_adult_imitexp_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = prop_adult_imitexp_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac"))

propimitexp_mtx_sp <- chip_per_activity_id_sp %>% 
  dplyr::select(id, language, activity, prop_adult_imitexp_avg_act) %>% 
  pivot_wider(names_from = activity, values_from = prop_adult_imitexp_avg_act) %>% 
  ungroup() %>% 
  dplyr::select(c("books", "play", "food", "routines", "conv", "ac"))
```




# Correlation Matrices - PER language
## Tokens - Rate
```{r}
# english
ggpairs(data = tokens_mtx_rate_en, 
        columns = 1:7, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 7)),
        title = "English - Tokens rate") + 
  theme_classic() + 
  theme(text= element_text(size = 18),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 15), 
        strip.text.x = element_text(face = "bold", size = 15)) 

# correlation matrices
rcorr(as.matrix(tokens_mtx_rate_en), type = c("pearson"))


# spanish
ggpairs(data = tokens_mtx_rate_sp, 
        columns = 1:7, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 7)),
        title = "Spanish - Tokens rate") + 
  theme_classic() + 
  theme(text= element_text(size = 18),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 15), 
        strip.text.x = element_text(face = "bold", size = 15)) 

# correlation matrices
rcorr(as.matrix(tokens_mtx_rate_sp), type = c("pearson"))

```


## Types - Rate
```{r}
# english
ggpairs(data = types_mtx_rate_en, 
        columns = 1:7, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 7)),
        title = "English - Types rate") + 
  theme_classic() + 
  theme(text= element_text(size = 18),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 15), 
        strip.text.x = element_text(face = "bold", size = 15)) 



# correlation matrices
rcorr(as.matrix(types_mtx_rate_en), type = c("pearson"))


# spanish
ggpairs(data = types_mtx_rate_sp, 
        columns = 1:7, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 7)),
        title = "Spanish - Types rate") + 
  theme_classic() + 
  theme(text= element_text(size = 18),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 15), 
        strip.text.x = element_text(face = "bold", size = 15)) 



# correlation matrices
rcorr(as.matrix(types_mtx_rate_sp), type = c("pearson"))
```



## MLUw
```{r}
# english
ggpairs(data = mlu_mtx_en, 
        columns = 1:7, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 11)),
        title = "English - MLUw") + 
  theme_classic() + 
  theme(text= element_text(size = 26),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 20), 
        strip.text.x = element_text(face = "bold", size = 20)) 

# correlation matrices
rcorr(as.matrix(mlu_mtx_en), type = c("pearson"))


# spanish
ggpairs(data = mlu_mtx_sp, 
        columns = 1:7, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 11)),
        title = "Spanish - MLUw") + 
  theme_classic() + 
  theme(text= element_text(size = 26),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 20), 
        strip.text.x = element_text(face = "bold", size = 20)) 

# correlation matrices
rcorr(as.matrix(mlu_mtx_sp), type = c("pearson"))

```




## PROP RESPONSES
```{r}
# english
ggpairs(data = propresp_mtx_en, 
        columns = 1:6, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 7)),
        title = "English - Prop Resp") + 
  theme_classic() + 
  theme(text= element_text(size = 18),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 15), 
        strip.text.x = element_text(face = "bold", size = 15)) 


# correlation matrices
rcorr(as.matrix(propresp_mtx_en), type = c("pearson"))


# spanish
ggpairs(data = propresp_mtx_sp, 
        columns = 1:6, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 7)),
        title = "Spanish - Prop Resp") + 
  theme_classic() + 
  theme(text= element_text(size = 18),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 15), 
        strip.text.x = element_text(face = "bold", size = 15)) 


# correlation matrices
rcorr(as.matrix(propresp_mtx_sp), type = c("pearson"))
```



## PROP IMIT and EXP
```{r}
# english
ggpairs(data = propimitexp_mtx_en, 
        columns = 1:6, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 7)),
        title = "English - Prop Imit/Exp") + 
  theme_classic() + 
  theme(text= element_text(size = 18),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 15), 
        strip.text.x = element_text(face = "bold", size = 15)) 


# correlation matrices
rcorr(as.matrix(propimitexp_mtx_en), type = c("pearson"))



# spanish
ggpairs(data = propimitexp_mtx_en, 
        columns = 1:6, 
        switch = 'y', 
        lower = list(continuous = my_custom_smooth),
        upper = list(continuous = wrap("cor", size = 7)),
        title = "Spanish - Prop Imit/Exp") + 
  theme_classic() + 
  theme(text= element_text(size = 18),
        strip.placement = "outside",
        strip.text.y = element_text(face = "bold", size = 15), 
        strip.text.x = element_text(face = "bold", size = 15)) 


# correlation matrices
rcorr(as.matrix(propimitexp_mtx_sp), type = c("pearson"))
```
